{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8505074,"sourceType":"datasetVersion","datasetId":4345642},{"sourceId":8624549,"sourceType":"datasetVersion","datasetId":5022440}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install patchify","metadata":{"_uuid":"0ad90ce5-35a0-4a0a-a339-b36aa1d65c6d","_cell_guid":"325bef66-f27b-4720-ae75-34da773af87f","trusted":true,"collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-06-06T15:50:22.823927Z","iopub.execute_input":"2024-06-06T15:50:22.824264Z","iopub.status.idle":"2024-06-06T15:50:36.525670Z","shell.execute_reply.started":"2024-06-06T15:50:22.824234Z","shell.execute_reply":"2024-06-06T15:50:36.524759Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage import io\nimport os\nimport random\nimport glob\nimport tifffile as tiff\nfrom patchify import patchify,unpatchify\nfrom tensorflow.keras import backend as K\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom skimage.util import view_as_blocks","metadata":{"_uuid":"c4befbe4-e208-4826-b1ac-5aa80f11b7ad","_cell_guid":"1d226df1-1383-4876-b1cd-740e5fbbcb13","trusted":true,"collapsed":false,"id":"eB4AmWYprUpY","execution":{"iopub.status.busy":"2024-06-06T15:50:39.457748Z","iopub.execute_input":"2024-06-06T15:50:39.458399Z","iopub.status.idle":"2024-06-06T15:50:51.840892Z","shell.execute_reply.started":"2024-06-06T15:50:39.458365Z","shell.execute_reply":"2024-06-06T15:50:51.839932Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n#Check if a GPU is available as accelerator\nif tf.config.list_physical_devices('GPU'):\n    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n    print('Using GPU')\nelse:\n    print('Using CPU')","metadata":{"_uuid":"f564a6f5-6335-459c-9684-1eeb7fe3df25","_cell_guid":"12dab76f-762b-4cb0-a8cc-c49af5b5536c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-06-06T15:50:56.373461Z","iopub.execute_input":"2024-06-06T15:50:56.374124Z","iopub.status.idle":"2024-06-06T15:50:56.544258Z","shell.execute_reply.started":"2024-06-06T15:50:56.374093Z","shell.execute_reply":"2024-06-06T15:50:56.543323Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Activation, MaxPool2D, Concatenate\n\n#Main Convolutional Block for Encoder and Decoder\ndef conv_block(input, num_filters):\n    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv3D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\n#Encoder Block\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPooling3D((2, 2, 2))(x)\n    return x, p\n\n#Decoder Block\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\n#U-Net building\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv3D(1, 1, padding=\"same\", activation='sigmoid')(d4)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model","metadata":{"_uuid":"2745f250-35ae-49cb-b64a-329d0c28ee84","_cell_guid":"338c0ffb-1482-46da-8a0a-466956c5f519","trusted":true,"collapsed":false,"id":"JJjF72sDscPR","execution":{"iopub.status.busy":"2024-06-06T15:54:15.478471Z","iopub.execute_input":"2024-06-06T15:54:15.479089Z","iopub.status.idle":"2024-06-06T15:54:15.495243Z","shell.execute_reply.started":"2024-06-06T15:54:15.479061Z","shell.execute_reply":"2024-06-06T15:54:15.494277Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Uploading MRI scan for training (sagittal view) with GT\noriginal_image = io.imread('data/Scansione2/320imageStack2.tif')\nprint(\"Dimensioni originali immagini: \", original_image.shape)\n\noriginal_mask = io.imread('data/Scansione2/320maskStack2.tif')\nprint(\"Dimensioni originali maschere: \", original_mask.shape)","metadata":{"_uuid":"fa2f1377-8c87-4688-bbd2-ea36d83f4a59","_cell_guid":"ba8311d1-13c4-4de5-9938-96eb5b03cba3","trusted":true,"collapsed":false,"id":"78_E3tDprob_","outputId":"a8c7f9b8-4e08-46f0-c8b5-b8de597cca90","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Uploading MRI scan for training (axial and coronal view) with GT\naug_img1 = io.imread('data/Scansione2/axial2.tif')\naug_img2 = io.imread('data/Scansione2/coronal2.tif')\n\naug_mask1 = io.imread('data/Scansione2/axial2_GT.tif')\naug_mask2 = io.imread('data/Scansione2/coronal2_GT.tif')","metadata":{"_uuid":"f6f64599-6523-4e0d-845c-ed29d734a82e","_cell_guid":"40e47645-5c72-4565-9541-188441028447","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Subvolumes creator function\ndef get_subvolumes(image,mask,step):\n    img_patches = patchify(image, (64,64,64), step=step)\n    mask_patches = patchify(mask, (64,64,64), step=step)\n    input_img = np.reshape(img_patches, (-1, img_patches.shape[3], img_patches.shape[4], img_patches.shape[5]))\n    input_mask = np.reshape(mask_patches, (-1, mask_patches.shape[3], mask_patches.shape[4], mask_patches.shape[5]))\n    \n    return input_img, input_mask","metadata":{"_uuid":"e22b16ae-4c2e-440c-bb65-c249907ee43a","_cell_guid":"db96b226-9553-4032-8f98-292a8f17db38","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_input_img, original_input_mask = get_subvolumes(original_image,original_mask,32)\naug_input_img1, aug_input_mask1 = get_subvolumes(aug_img1,aug_mask1,32)\naug_input_img2, aug_input_mask2 = get_subvolumes(aug_img2,aug_mask2,32)\n\nprint(original_input_img.shape, original_input_mask.shape)\nprint(aug_input_img1.shape, aug_input_mask1.shape)\nprint(aug_input_img2.shape, aug_input_mask2.shape)\n\ninput_img = np.concatenate((original_input_img,aug_input_img1), axis=0)\ninput_img = np.concatenate((input_img,aug_input_img2), axis=0)\n\ninput_mask = np.concatenate((original_input_mask,aug_input_mask1), axis=0)\ninput_mask = np.concatenate((input_mask,aug_input_mask2), axis=0)\n\nprint(input_img.shape)\ninput_shape = input_img.shape[0]","metadata":{"_uuid":"c50bd769-268f-4d3f-ad73-19f4dd376dfd","_cell_guid":"d4e45d6a-9c14-4f50-bbc4-926ecd075e08","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Normalization and reshaping for train and validation set splitting\ntrain_img = np.stack((input_img,), axis=-1)\ntrain_img = train_img / 255.\ntrain_mask = np.expand_dims(input_mask, axis=4)\n\nX_train, X_test, Y_train, Y_test = train_test_split(train_img, train_mask, test_size = 0.20, random_state = 42)","metadata":{"_uuid":"6a5168bf-7d12-4ae3-9144-56af79a2e680","_cell_guid":"7f5f6c9e-4d6d-49f3-a3a6-09f413e3721e","trusted":true,"collapsed":false,"id":"TJ1xcNX6uq7y","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#U-Net\npatch_size = 64\nchannels=1\n\nLR = 0.0001\noptim = tf.keras.optimizers.Adam(LR)\n\nmodel = build_unet((patch_size,patch_size,patch_size,channels))\n\nmodel.compile(optimizer = optim, loss='binary_crossentropy', metrics=['accuracy'])\nprint(model.summary())","metadata":{"_uuid":"93402d5b-c6a0-445d-866a-8b8cf9b95d62","_cell_guid":"371ad09f-ffb5-4789-811d-1b5beecb0535","trusted":true,"collapsed":false,"id":"9MOWDgHOvwOF","execution":{"iopub.status.busy":"2024-06-06T15:56:06.725062Z","iopub.execute_input":"2024-06-06T15:56:06.725883Z","iopub.status.idle":"2024-06-06T15:56:07.360105Z","shell.execute_reply.started":"2024-06-06T15:56:06.725853Z","shell.execute_reply":"2024-06-06T15:56:07.358905Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.input_shape)\nprint(X_train.shape)\nprint(model.output_shape)\nprint(Y_train.shape)\nprint(\"-------------------\")\nprint(X_train.max())","metadata":{"_uuid":"454a716c-e52b-468e-8540-cfc5fd341ee0","_cell_guid":"43a47b61-36a2-4f7b-9fbb-5d951e28fa15","trusted":true,"collapsed":false,"id":"HE2wXdtZwWnD","outputId":"50c709f2-613f-48c0-8848-eaab0d6210c8","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checkpoint callback to save best model according to validation loss\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nbest_mcp_save = ModelCheckpoint('ckp/best_model-{val_loss:.4f}.keras', save_best_only=True, monitor='val_loss', mode='min')","metadata":{"_uuid":"8745d93b-8f69-44dd-b82c-8901ddf170dc","_cell_guid":"0f19fa10-b631-45ac-bfe0-c78414fe323c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Model training\nhistory = model.fit(X_train, Y_train, batch_size=10, epochs=100, shuffle=True, verbose=1, callbacks = [best_mcp_save], validation_data=(X_test, Y_test))","metadata":{"_uuid":"72d02aed-3c36-43be-8635-d0787e42ca7c","_cell_guid":"57110c49-e2b7-402d-a163-7ff4e39f81de","trusted":true,"collapsed":false,"id":"NmVjvZ3gwhgJ","outputId":"10cffb7a-1f53-473c-e08d-71744cb3fa22","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'y', label='Training Acc')\nplt.plot(epochs, val_acc, 'r', label='Validation Acc')\nplt.title('Training and validation Acc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"_uuid":"0e9ec29c-93bd-457e-88d8-31da54b3caa0","_cell_guid":"20b8e071-8fd9-4870-ba78-fa078fbdff09","trusted":true,"collapsed":false,"id":"8mCPC2PywD1F","outputId":"2fe57936-4176-4240-d970-d2eb142f0e1a","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.models import load_model\nmy_model = model\n\n#If already got the model:\n#my_model = load_model('/kaggle/working/best_epoch-49-0.0024.keras')","metadata":{"_uuid":"f6d677fc-0755-4b7a-9ec9-a6cde25eb3fc","_cell_guid":"806b6868-b746-4e72-8ee8-630f2a888aba","trusted":true,"collapsed":false,"id":"ufk2halV2SKK","scrolled":true,"execution":{"iopub.status.busy":"2024-06-06T15:51:36.641444Z","iopub.execute_input":"2024-06-06T15:51:36.642274Z","iopub.status.idle":"2024-06-06T15:51:37.407068Z","shell.execute_reply.started":"2024-06-06T15:51:36.642232Z","shell.execute_reply":"2024-06-06T15:51:37.405812Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Prediction on a new MRI scan \nlarge_image = io.imread('data/Scansione1/320imageStack.tif') \nprint(large_image.shape) \npatches = patchify(large_image,(64,64,64), step=32)","metadata":{"_uuid":"47ffca82-3db5-4822-a0c1-6d1a3bfe48e8","_cell_guid":"acaa5b6c-8bd7-4973-b1f4-75d984983630","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Prediction on single patches\npredicted_patches = []\nfor i in range(patches.shape[0]):\n  for j in range(patches.shape[1]):\n    for k in range(patches.shape[2]):\n      single_patch = patches[i,j,k, :,:,:]\n      single_patch_ch = np.stack((single_patch,), axis=-1)\n      single_patch_ch = single_patch_ch/255.\n      single_patch_ch_input = np.expand_dims(single_patch_ch, axis=0)\n      single_patch_prediction = (my_model.predict(single_patch_ch_input) >= 0.5) #Thresholding\n      predicted_patches.append(single_patch_prediction)","metadata":{"_uuid":"7ff23180-f696-4660-9fb4-0810d54e60fc","_cell_guid":"d685b0b5-4e27-401e-877e-02eddc58f11c","trusted":true,"collapsed":false,"id":"t1a6B6Ca2eeq","outputId":"d8aac449-c13e-4360-d7ec-12a89781755d","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final image reconstruction\npredicted_patches = np.array(predicted_patches)\nprint(predicted_patches.shape)\n\npredicted_patches_reshaped = np.reshape(predicted_patches,\n                                        (patches.shape[0], patches.shape[1], patches.shape[2],\n                                         patches.shape[3], patches.shape[4], patches.shape[5]) )\nprint(predicted_patches_reshaped.shape)","metadata":{"_uuid":"32940dd6-2667-4d23-bfa8-593134055456","_cell_guid":"682a9681-5c65-4223-958e-c17534df9d60","trusted":true,"collapsed":false,"id":"BKdwcDPiOqk2","outputId":"ccd82a58-bab3-4142-b433-97cddf80f97b","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Reconstruct the 3D volume from the predicted patches, using overlap\ndef overlap_and_add(blocks, output_shape, block_shape, overlap):\n    reconstructed_volume = np.zeros(output_shape, dtype=blocks.dtype)\n    rows, cols, depths = output_shape\n    num_blocks_z, num_blocks_x, num_blocks_y, _, _, _ = blocks.shape\n\n    step_row = block_shape[0] - overlap\n    step_col = block_shape[1] - overlap\n    step_depth = block_shape[2] - overlap\n\n    for i in range(0, num_blocks_z * step_row, step_row):\n        for j in range(0, num_blocks_x * step_col, step_col):\n            for k in range(0, num_blocks_y * step_depth, step_depth):\n                block = blocks[i // step_row, j // step_col, k // step_depth]\n                i0 = min(i, rows - block_shape[0])\n                i1 = min(i + block_shape[0], rows)\n                j0 = min(j, cols - block_shape[1])\n                j1 = min(j + block_shape[1], cols)\n                k0 = min(k, depths - block_shape[2])\n                k1 = min(k + block_shape[2], depths)\n                reconstructed_volume[i0:i1, j0:j1, k0:k1] += block[:i1 - i0, :j1 - j0, :k1 - k0]\n\n    return reconstructed_volume\n\nreconstructed_image = overlap_and_add(predicted_patches_reshaped, output_shape=(large_image.shape[0], large_image.shape[1], large_image.shape[2]), block_shape=(64, 64, 64), overlap=32)\nprint(reconstructed_image.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}